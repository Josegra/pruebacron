name: Ejecutar Scraper de FBref y Guardar CSV en Repositorio

on:
  schedule:
    # Ejecuta todos los días a las 10:30 UTC (12:30 CEST si estás en UTC+2)
    - cron: '30 10 * * *'
  workflow_dispatch:

jobs:
  scrape_and_commit:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10' # O la versión que prefieras

      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install pandas lxml html5lib unidecode # Solo estas dependencias son necesarias

      - name: Ejecutar script standard_scrape.py
        run: python standard_scrape.py

      - name: Commit y Push del archivo CSV
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "chore: Actualizar datos de jugadores (CSV) [skip ci]"
          branch: main # O tu rama principal
          file_pattern: ./data/big5_player_stats.csv # Asegúrate que coincida con lo que genera tu script
          commit_user_name: GitHub Actions Bot
          commit_user_email: actions@github.com
          commit_author: GitHub Actions Bot <actions@github.com>
